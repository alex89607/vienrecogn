## Таймлайн проекта: 16.09.2024 – 27.09.2024

### **Неделя 1**

---

#### **Понедельник, 16 сентября 2024**

**Задачи:**

- **Сбор и организация данных:**
  - Собрать все доступные изображения и соответствующие JSON-файлы разметки.
  - Организовать данные в структурированные папки для удобства обработки.

**Майлстоун (17:45):**

- Все исходные данные собраны и организованы в соответствующих директориях.

**Возможные трудности:**

- Разные форматы файлов или несоответствие в именовании могут усложнить процесс организации данных.

---

#### **Вторник, 17 сентября 2024**

**Задачи:**

- **Обработка аннотаций:**
  - Разработать и отладить код для преобразования разметки из JSON-файлов в маски изображений.
  - Проверить корректность масок на нескольких примерах.

**Майлстоун (17:45):**

- Все JSON-аннотации успешно преобразованы в маски изображений.

**Возможные трудности:**

- Сложности с декодированием RLE-формата и обработкой возможных ошибок в данных.
- Несоответствие размеров изображений и масок.

---

#### **Среда, 18 сентября 2024**

**Задачи:**

- **Создание набора данных:**
  - Разделить данные на обучающий и тестовый наборы (например, 80% и 20%).
  - Реализовать аугментацию данных (повороты, масштабирование, изменение яркости и контраста).

**Майлстоун (17:45):**

- Данные разделены и аугментированы, готовы для обучения модели.

**Возможные трудности:**

- Избегать аугментаций, которые могут исказить ключевые особенности вен.
- Убедиться, что аугментация не приводит к утечке данных между наборами.

---

#### **Четверг, 19 сентября 2024**

**Задачи:**

- **Установка и настройка YOLOv5:**
  - Установить YOLOv5 и все необходимые зависимости.
  - Настроить окружение для обучения модели сегментации.

**Майлстоун (17:45):**

- YOLOv5 установлен и настроен для задачи сегментации.

**Возможные трудности:**

- Возможные конфликты версий библиотек или проблемы с установкой зависимостей.

---

#### **Пятница, 20 сентября 2024**

**Задачи:**

- **Подготовка данных для YOLOv5:**
  - Конвертировать маски и изображения в формат, совместимый с YOLOv5 (например, COCO).
  - Создать файл `data.yaml` с необходимой конфигурацией.

**Майлстоун (17:45):**

- Данные подготовлены и организованы в требуемом формате для обучения YOLOv5.

**Возможные трудности:**

- Сложности с конвертацией формата масок в аннотации YOLO.
- Проверка корректности аннотаций и соответствия изображений.

---

### **Неделя 2**

---

#### **Понедельник, 23 сентября 2024**

**Задачи:**

- **Настройка гиперпараметров:**
  - Определить оптимальные значения для скорости обучения, функции потерь и других параметров.
  - Подготовить скрипты для запуска обучения.

- **Запуск обучения модели:**
  - Начать процесс обучения модели на подготовленных данных.

**Майлстоун (17:45):**

- Модель запущена на обучение с первоначальными настройками.

**Возможные трудности:**

- Выбор оптимальных гиперпараметров может потребовать дополнительных экспериментов.
- Возможные ошибки при запуске обучения.

---

#### **Вторник, 24 сентября 2024**

**Задачи:**

- **Мониторинг процесса обучения:**
  - Отслеживать метрики обучения (потери, точность и т.д.).
  - Вносить корректировки в гиперпараметры при необходимости.

**Майлстоун (17:45):**

- Обучение модели продолжается, метрики находятся в допустимых пределах.

**Возможные трудности:**

- Переобучение модели из-за малого объема данных.
- Необходимость остановки и перезапуска обучения с измененными параметрами.

---

#### **Среда, 25 сентября 2024**

**Задачи:**

- **Завершение обучения модели:**
  - Дождаться завершения обучения модели.
  - Сохранить окончательные веса модели.

- **Предварительная оценка:**
  - Провести предварительную оценку модели на валидационном наборе данных.

**Майлстоун (17:45):**

- Обучение завершено, модель готова к полной оценке.

**Возможные трудности:**

- Если результаты неудовлетворительны, может потребоваться дополнительное обучение или корректировка данных.

---

#### **Четверг, 26 сентября 2024**

**Задачи:**

- **Оценка модели:**
  - Оценить производительность модели с использованием метрик mAP, IoU и других.
  - Проанализировать ошибки и области для улучшения.

- **Тестирование на новых данных:**
  - Проверить модель на тестовом наборе данных.

**Майлстоун (17:45):**

- Модель оценена, результаты документированы.

**Возможные трудности:**

- Интерпретация метрик и понимание того, где модель ошибается.
- Возможно, потребуется дополнительная итерация обучения.

---

#### **Пятница, 27 сентября 2024**

**Задачи:**

- **Предсказание на новых изображениях:**
  - Использовать модель для предсказания областей инъекций на новых, ранее невидимых изображениях.
  - Визуализировать результаты и сравнить их с ожидаемыми.

- **Документация и подготовка отчета:**
  - Составить отчет о проделанной работе, включив в него результаты, выводы и рекомендации.

**Майлстоун (17:45):**

- Предсказания на новых изображениях выполнены, проект завершен и задокументирован.

**Возможные трудности:**

- Возможные проблемы с генерацией предсказаний на новых данных.
- Оформление и структурирование отчета.

---

## Участки, представляющие трудности

1. **Обработка аннотаций (17 сентября):**

   - **Описание проблемы:** Сложности с декодированием RLE-формата из JSON-файлов и преобразованием его в корректные маски.
   - **Рекомендации:**
     - Внимательно изучить структуру JSON-файлов.
     - Написать тестовые сценарии для проверки корректности декодирования.
     - При необходимости обратиться к дополнительным источникам или сообществам разработчиков.

2. **Аугментация данных (18 сентября):**

   - **Описание проблемы:** Риск исказить важные особенности вен, что может негативно сказаться на обучении модели.
   - **Рекомендации:**
     - Применять только те аугментации, которые сохраняют ключевые характеристики изображения.
     - Избегать слишком агрессивных трансформаций.

3. **Конвертация данных в формат YOLO (20 сентября):**

   - **Описание проблемы:** Требуется преобразовать сегментационные маски в формат аннотаций, совместимый с YOLOv5, что может быть нетривиальной задачей.
   - **Рекомендации:**
     - Изучить требования YOLOv5 к формату данных для сегментации.
     - Использовать существующие инструменты или написать скрипты для автоматизации процесса.

4. **Обучение модели на небольшом датасете (23–25 сентября):**

   - **Описание проблемы:** Малый объем данных (53 изображения) может привести к переобучению модели и плохой обобщающей способности.
   - **Рекомендации:**
     - Рассмотреть возможность увеличения датасета.
     - Использовать методы регуляризации.
     - Применить кросс-валидацию.

5. **Оценка модели (26 сентября):**

   - **Описание проблемы:** Выбор и интерпретация метрик для сегментации могут быть сложными.
   - **Рекомендации:**
     - Использовать метрики, специфичные для задач сегментации (IoU, Dice Coefficient).
     - Сравнивать результаты с базовыми значениями или другими моделями.

---

## Код для обработки областей изображения из JSON

Разметка в вашем JSON-файле представлена в формате RLE (Run-Length Encoding). Ниже приведен код для преобразования этой разметки в маски изображений.

### Установка необходимых библиотек

```bash
pip install numpy pillow pycocotools
```

### Код

```python
import json
import numpy as np
from PIL import Image
import os
import zlib
from pycocotools import mask as maskutils

def decode_rle(rle_array, image_shape):
    """
    Декодирует RLE-массив в бинарную маску.

    Args:
        rle_array (list of int): RLE-данные в виде списка чисел.
        image_shape (tuple): Размер изображения в формате (height, width).

    Returns:
        np.ndarray: Бинарная маска.
    """
    try:
        # Преобразуем список чисел в байты
        rle_bytes = bytes(rle_array)
        # Распаковываем данные с помощью zlib
        decompressed_bytes = zlib.decompress(rle_bytes)
        # Декодируем байты в строку
        rle_string = decompressed_bytes.decode('utf-8')
        # Преобразуем строку в список целых чисел
        counts = [int(s) for s in rle_string.split()]
        # Создаем RLE-объект
        rle = {'counts': counts, 'size': list(image_shape)}
        # Декодируем маску с помощью pycocotools
        mask = maskutils.decode(rle)
        return mask
    except Exception as e:
        print(f"Ошибка при декодировании RLE: {e}")
        return None

def json_to_masks(json_file, images_dir, masks_dir):
    """
    Преобразует разметку из JSON-файла в маски и сохраняет их.

    Args:
        json_file (str): Путь к JSON-файлу с разметкой.
        images_dir (str): Директория с исходными изображениями.
        masks_dir (str): Директория для сохранения масок.
    """
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    if not os.path.exists(masks_dir):
        os.makedirs(masks_dir)

    if not os.path.exists(images_dir):
        os.makedirs(images_dir)
    
    # Обходим каждый элемент в JSON
    for task in data:
        task_id = task['id']
        annotations = task.get('annotations', [])
        for annotation in annotations:
            annotation_id = annotation['id']
            results = annotation.get('result', [])
            for res in results:
                if res['type'] == 'brushlabels':
                    value = res['value']
                    rle_array = value.get('rle')
                    if not rle_array:
                        continue
                    width = res.get('original_width')
                    height = res.get('original_height')
                    if not width or not height:
                        continue
                    image_shape = (height, width)
                    # Декодируем RLE в маску
                    mask = decode_rle(rle_array, image_shape)
                    if mask is None:
                        continue
                    # Преобразуем маску в изображение
                    mask_image = Image.fromarray(mask * 255).convert('L')
                    # Формируем имя файла
                    mask_filename = f"{task_id}.png"
                    mask_filepath = os.path.join(masks_dir, mask_filename)
                    # Сохраняем маску
                    mask_image.save(mask_filepath)
                    print(f"Маска сохранена: {mask_filepath}")
                    
                    # Сохраняем исходное изображение (если необходимо)
                    image_url = task['data']['image']
                    image_filename = os.path.basename(image_url)
                    image_path = os.path.join(images_dir, image_filename)
                    if not os.path.exists(image_path):
                        # Загрузите изображение из image_url и сохраните его в images_dir
                        pass  # Здесь можно добавить код для загрузки изображения
```

---

## Рекомендуемый пайплайн для обучения сети с использованием YOLO

### Шаг 1: Подготовка данных для YOLO

YOLO требует специального формата данных. Для сегментации с использованием YOLOv5 необходимо подготовить данные в формате COCO или создавая собственные файлы аннотаций.

### Шаг 2: Установка YOLOv5

Склонируйте репозиторий YOLOv5:

```bash
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
pip install -r requirements.txt
```

### Шаг 3: Организация файловой структуры

Создайте структуру директорий:

```
dataset/
├── images/
│   ├── train/
│   ├── val/
├── labels/
│   ├── train/
│   ├── val/
```

- **images/train/**: Изображения для обучения.
- **images/val/**: Изображения для валидации.
- **labels/train/**: Аннотации для обучения в формате YOLO.
- **labels/val/**: Аннотации для валидации в формате YOLO.

### Шаг 4: Преобразование масок в аннотации YOLO

Используйте скрипт для преобразования масок в полилинии или контуры и сохранения их в формате YOLO.

### Шаг 5: Создание файла конфигурации данных

Создайте файл `data.yaml`:

```yaml
train: dataset/images/train
val: dataset/images/val

nc: 1  # количество классов
names: ['Injection_Site']
```

### Шаг 6: Обучение модели

Запустите обучение:

```bash
python train.py --img 640 --batch 16 --epochs 100 --data data.yaml --weights yolov5s-seg.pt --cache
```

- **--img**: Размер изображения.
- **--batch**: Размер батча.
- **--epochs**: Количество эпох.
- **--data**: Путь к файлу конфигурации данных.
- **--weights**: Предварительно обученные веса для сегментации.
- **--cache**: Кэширование данных в оперативной памяти для ускорения обучения.

### Шаг 7: Оценка модели

После обучения модель будет сохранена в `runs/train/exp/`. Вы можете использовать ее для предсказания на новых изображениях.

---

## Python код (Jupyter Notebook) для предсказания на новых изображениях

Ниже приведен пример кода, который загружает обученную модель и выполняет предсказание на новых изображениях.

### Установка зависимостей

```python
!git clone https://github.com/ultralytics/yolov5.git
%cd yolov5
!pip install -r requirements.txt
```

### Импорт библиотек

```python
import torch
from matplotlib import pyplot as plt
import cv2
import numpy as np
from PIL import Image
```

### Загрузка модели

```python
# Замените путь на путь к вашей обученной модели
model = torch.hub.load('ultralytics/yolov5', 'custom', path='path/to/your/best.pt', force_reload=True)
```

### Предсказание на новых изображениях

```python
# Путь к папке с тестовыми изображениями
test_images_path = 'path/to/test/images/'

# Получаем список файлов изображений
import os
test_images = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path) if img.endswith(('.jpg', '.png'))]

# Выполняем предсказание и отображаем результаты
for img_path in test_images:
    results = model(img_path)
    # Отображаем изображение с наложенной маской
    results.render()  # Это сохранит изображения с предсказаниями в results.imgs
    plt.figure(figsize=(12,8))
    plt.imshow(results.imgs[0])
    plt.axis('off')
    plt.show()
```

### Дополнительные настройки

Вы можете получить подробную информацию о предсказаниях:

```python
# Получаем DataFrame с результатами
df = results.pandas().xyxy[0]
print(df)
```

---

## Заключение

Предоставленный план и код помогут вам:

- Подготовить данные из ваших JSON-разметок.
- Обучить модель YOLO для задачи сегментации областей для инъекций.
- Выполнить предсказание на новых изображениях и визуализировать результаты.

**Примечания**:

- **Загрузка изображений**: В коде для преобразования JSON-разметки необходимо добавить код для загрузки исходных изображений, если они не локальные.
- **Аугментация данных**: Рекомендуется использовать аугментацию данных для улучшения обобщающей способности модели.
- **Тестирование модели**: Убедитесь, что тестовые изображения не использовались в процессе обучения для получения объективной оценки модели.

---

**Важно**: При работе с медицинскими данными и моделями необходимо соблюдать все соответствующие этические нормы и стандарты конфиденциальности.